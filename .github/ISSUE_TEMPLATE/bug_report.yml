name: Bug Report
description: Report a bug or unexpected behavior in Ralph AI
title: "[Bug]: "
labels: ["bug", "needs-triage"]
body:
  - type: markdown
    attributes:
      value: |
        Thanks for taking the time to report a bug! Please fill out the sections below to help us diagnose and fix the issue.

  - type: textarea
    id: description
    attributes:
      label: Bug Description
      description: A clear and concise description of what the bug is.
      placeholder: Tell us what went wrong
    validations:
      required: true

  - type: textarea
    id: reproduction
    attributes:
      label: Steps to Reproduce
      description: Detailed steps to reproduce the behavior
      placeholder: |
        1. Run command './ralph_loop.sh "..."'
        2. Wait for iteration X
        3. See error
    validations:
      required: true

  - type: textarea
    id: expected
    attributes:
      label: Expected Behavior
      description: What should have happened instead?
      placeholder: Describe the expected outcome
    validations:
      required: true

  - type: textarea
    id: actual
    attributes:
      label: Actual Behavior
      description: What actually happened?
      placeholder: Describe what you observed
    validations:
      required: true

  - type: dropdown
    id: component
    attributes:
      label: Which component is affected?
      options:
        - Translator Agent
        - Orchestrator Agent
        - Engineer Agent
        - Designer Agent
        - ASIC System
        - Message Bus
        - Memory/Vector DB
        - Web UI
        - Voice Interface
        - Vision Module
        - Docker Sandbox
        - Other/Unknown
    validations:
      required: true

  - type: textarea
    id: logs
    attributes:
      label: Relevant Logs
      description: Please paste relevant log output (from ralph.log or console)
      render: shell
      placeholder: Paste logs here

  - type: textarea
    id: environment
    attributes:
      label: Environment
      description: System information
      value: |
        - OS: [e.g., CachyOS, Ubuntu 22.04]
        - Python Version: [e.g., 3.10.12]
        - Ollama Version: [run `ollama --version`]
        - RAM: [e.g., 64GB]
        - GPU: [e.g., RX 9070 XT, 16GB VRAM]
      render: markdown
    validations:
      required: true

  - type: textarea
    id: models
    attributes:
      label: Installed Models
      description: Output of `ollama list`
      render: shell
      placeholder: Paste output of `ollama list` here

  - type: textarea
    id: context
    attributes:
      label: Additional Context
      description: Any other context about the problem
      placeholder: Add any other relevant information

  - type: checkboxes
    id: checklist
    attributes:
      label: Pre-submission Checklist
      options:
        - label: I have searched existing issues to ensure this is not a duplicate
          required: true
        - label: I have included relevant logs and error messages
          required: true
        - label: I have verified all required Ollama models are installed
          required: true
